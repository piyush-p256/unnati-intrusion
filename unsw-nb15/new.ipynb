{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ouHHDC6SdLo8",
        "outputId": "4776e728-04b4-4a3d-f940-b2da34f6842b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Preprocessing training data...\n",
            "Preprocessing testing data...\n",
            "Training XGBoost classifier...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [12:08:07] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluating on test data...\n",
            "Test Accuracy: 85.41%\n",
            "                precision    recall  f1-score   support\n",
            "\n",
            "      Analysis       0.00      0.00      0.00      2000\n",
            "      Backdoor       0.96      0.07      0.13      1746\n",
            "           DoS       0.34      0.58      0.43     12264\n",
            "      Exploits       0.71      0.68      0.70     33393\n",
            "       Fuzzers       0.96      0.86      0.91     18184\n",
            "       Generic       0.99      0.98      0.99     40000\n",
            "        Normal       1.00      1.00      1.00     56000\n",
            "Reconnaissance       0.92      0.75      0.82     10491\n",
            "     Shellcode       0.63      0.68      0.65      1133\n",
            "         Worms       0.69      0.52      0.59       130\n",
            "\n",
            "      accuracy                           0.85    175341\n",
            "     macro avg       0.72      0.61      0.62    175341\n",
            "  weighted avg       0.87      0.85      0.86    175341\n",
            "\n",
            "Saving model and preprocessors...\n",
            "Artifacts saved.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "import xgboost as xgb\n",
        "import joblib\n",
        "\n",
        "# --------------\n",
        "# CONFIGURATION\n",
        "TRAIN_CSV = '/content/UNSW_NB15_training-set.csv'\n",
        "TEST_CSV = '/content/UNSW_NB15_testing-set.csv'\n",
        "MODEL_PATH = '/content/threat_detection_xgb_model.pkl'\n",
        "SCALER_PATH = '/content/threat_detection_scaler.pkl'\n",
        "TARGET_ENCODER_PATH = '/content/threat_detection_target_encoder.pkl'\n",
        "FEATURE_ENCODERS_PATH = '/content/threat_detection_feature_encoders.pkl'\n",
        "\n",
        "# 1. Load datasets\n",
        "train_df = pd.read_csv(TRAIN_CSV)\n",
        "test_df = pd.read_csv(TEST_CSV)\n",
        "\n",
        "# 2. Preprocessing for training data\n",
        "def preprocess_train(df):\n",
        "    df = df.copy()\n",
        "    # Drop irrelevant columns\n",
        "    df = df.drop(columns=['id', 'attack_id'], errors='ignore')\n",
        "    # Extract and encode target\n",
        "    y = df.pop('attack_cat')\n",
        "    target_encoder = LabelEncoder()\n",
        "    y_enc = target_encoder.fit_transform(y)\n",
        "    # Features\n",
        "    X = df\n",
        "    # Encode categorical features\n",
        "    cat_cols = X.select_dtypes(include=['object']).columns.tolist()\n",
        "    feature_encoders = {}\n",
        "    for col in cat_cols:\n",
        "        le = LabelEncoder()\n",
        "        X[col] = le.fit_transform(X[col].astype(str))\n",
        "        feature_encoders[col] = {'classes': le.classes_.tolist(),\n",
        "                                  'mapping': {cls: idx for idx, cls in enumerate(le.classes_)}}\n",
        "    # Scale\n",
        "    scaler = StandardScaler()\n",
        "    X_scaled = scaler.fit_transform(X)\n",
        "    return X_scaled, y_enc, scaler, target_encoder, feature_encoders, X.columns.tolist()\n",
        "\n",
        "# 3. Preprocessing for test data\n",
        "def preprocess_test(df, scaler, target_encoder, feature_encoders, feature_cols):\n",
        "    df = df.copy()\n",
        "    df = df.drop(columns=['id', 'attack_id'], errors='ignore')\n",
        "    # Encode target if present\n",
        "    if 'attack_cat' in df:\n",
        "        y = df.pop('attack_cat')\n",
        "        y_enc = target_encoder.transform(y)\n",
        "    else:\n",
        "        y_enc = None\n",
        "    # Features\n",
        "    X = df.reindex(columns=feature_cols)\n",
        "    # Handle categorical\n",
        "    for col, enc in feature_encoders.items():\n",
        "        X[col] = X[col].astype(str).map(enc['mapping']).fillna(-1).astype(int)\n",
        "    # Scale\n",
        "    X_scaled = scaler.transform(X)\n",
        "    return X_scaled, y_enc\n",
        "\n",
        "# 4. Train & evaluate\n",
        "print(\"Preprocessing training data...\")\n",
        "X_train, y_train, scaler, target_enc, feature_encoders, feature_cols = preprocess_train(train_df)\n",
        "print(\"Preprocessing testing data...\")\n",
        "X_test, y_test = preprocess_test(test_df, scaler, target_enc, feature_encoders, feature_cols)\n",
        "\n",
        "print(\"Training XGBoost classifier...\")\n",
        "clf = xgb.XGBClassifier(\n",
        "    objective='multi:softmax',\n",
        "    num_class=len(target_enc.classes_),\n",
        "    n_estimators=200,\n",
        "    learning_rate=0.1,\n",
        "    max_depth=6,\n",
        "    subsample=0.8,\n",
        "    colsample_bytree=0.8,\n",
        "    use_label_encoder=False,\n",
        "    eval_metric='mlogloss'\n",
        ")\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "print(\"Evaluating on test data...\")\n",
        "y_pred = clf.predict(X_test)\n",
        "acc = accuracy_score(y_test, y_pred)\n",
        "print(f\"Test Accuracy: {acc * 100:.2f}%\")\n",
        "print(classification_report(y_test, y_pred, target_names=target_enc.classes_))\n",
        "\n",
        "# 5. Save artifacts\n",
        "print(\"Saving model and preprocessors...\")\n",
        "joblib.dump(clf, MODEL_PATH)\n",
        "joblib.dump(scaler, SCALER_PATH)\n",
        "joblib.dump(target_enc, TARGET_ENCODER_PATH)\n",
        "joblib.dump(feature_encoders, FEATURE_ENCODERS_PATH)\n",
        "joblib.dump(feature_cols, '/content/feature_columns.pkl')\n",
        "print(\"Artifacts saved.\")\n",
        "\n",
        "# 6. Inference function for real-world data without labels\n",
        "def infer(input_df):\n",
        "    \"\"\"\n",
        "    input_df: DataFrame with same feature columns (may include id, attack_id, but no attack_cat)\n",
        "    returns: array of predicted attack categories\n",
        "    \"\"\"\n",
        "    X_scaled, _ = preprocess_test(input_df, scaler, target_enc, feature_encoders, feature_cols)\n",
        "    preds = clf.predict(X_scaled)\n",
        "    return target_enc.inverse_transform(preds)\n",
        "\n",
        "#  Example usage for inference:\n",
        "# new_data = pd.read_csv('new_traffic.csv')  # must have same raw features\n",
        "# predictions = infer(new_data)\n",
        "# print(predictions)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "import xgboost as xgb\n",
        "from imblearn.over_sampling import SMOTE\n",
        "import joblib\n",
        "\n",
        "# --------------\n",
        "# CONFIGURATION\n",
        "TRAIN_CSV = '/content/UNSW_NB15_training-set.csv'\n",
        "TEST_CSV = '/content/UNSW_NB15_testing-set.csv'\n",
        "MODEL_PATH = '/content/new/threat_detection_xgb_model.pkl'\n",
        "SCALER_PATH = '/content/new/threat_detection_scaler.pkl'\n",
        "TARGET_ENCODER_PATH = '/content/new/threat_detection_target_encoder.pkl'\n",
        "FEATURE_ENCODERS_PATH = '/content/new/threat_detection_feature_encoders.pkl'\n",
        "\n",
        "# 1. Load datasets\n",
        "def load_data(path):\n",
        "    return pd.read_csv(path)\n",
        "\n",
        "train_df = load_data(TRAIN_CSV)\n",
        "test_df = load_data(TEST_CSV)\n",
        "\n",
        "# 2. Preprocessing functions\n",
        "def preprocess_train(df):\n",
        "    df = df.copy()\n",
        "    df.drop(columns=['id', 'attack_id'], errors='ignore', inplace=True)\n",
        "    y = df.pop('attack_cat')\n",
        "    target_enc = LabelEncoder()\n",
        "    y_enc = target_enc.fit_transform(y)\n",
        "    X = df\n",
        "    cat_cols = X.select_dtypes(include=['object']).columns.tolist()\n",
        "    feat_enc = {}\n",
        "    for col in cat_cols:\n",
        "        le = LabelEncoder()\n",
        "        X[col] = le.fit_transform(X[col].astype(str))\n",
        "        feat_enc[col] = {'classes': le.classes_.tolist(), 'mapping': {cls: idx for idx, cls in enumerate(le.classes_)}}\n",
        "    scaler = StandardScaler()\n",
        "    X_scaled = scaler.fit_transform(X)\n",
        "    return X_scaled, y_enc, scaler, target_enc, feat_enc, X.columns.tolist()\n",
        "\n",
        "def preprocess_test(df, scaler, target_enc, feat_enc, feat_cols):\n",
        "    df = df.copy()\n",
        "    df.drop(columns=['id', 'attack_id'], errors='ignore', inplace=True)\n",
        "    if 'attack_cat' in df:\n",
        "        y = df.pop('attack_cat')\n",
        "        y_enc = target_enc.transform(y)\n",
        "    else:\n",
        "        y_enc = None\n",
        "    X = df.reindex(columns=feat_cols)\n",
        "    for col, enc in feat_enc.items():\n",
        "        X[col] = X[col].astype(str).map(enc['mapping']).fillna(-1).astype(int)\n",
        "    X_scaled = scaler.transform(X)\n",
        "    return X_scaled, y_enc\n",
        "\n",
        "# 3. Prepare training data\n",
        "X_train_raw, y_train_raw, scaler, target_enc, feat_enc, feat_cols = preprocess_train(train_df)\n",
        "# Apply SMOTE to balance classes\n",
        "sm = SMOTE(random_state=42)\n",
        "X_train, y_train = sm.fit_resample(X_train_raw, y_train_raw)\n",
        "\n",
        "# 4. Hyperparameter tuning with RandomizedSearchCV\n",
        "param_dist = {\n",
        "    'n_estimators': [100, 200, 300],\n",
        "    'max_depth': [4, 6, 8],\n",
        "    'learning_rate': [0.01, 0.05, 0.1],\n",
        "    'subsample': [0.7, 0.8, 1.0],\n",
        "    'colsample_bytree': [0.7, 0.8, 1.0]\n",
        "}\n",
        "\n",
        "base_clf = xgb.XGBClassifier(objective='multi:softmax', num_class=len(target_enc.classes_),\n",
        "                             use_label_encoder=False, eval_metric='mlogloss', random_state=42)\n",
        "search = RandomizedSearchCV(base_clf, param_distributions=param_dist, n_iter=10,\n",
        "                            scoring='accuracy', cv=3, verbose=1, random_state=42, n_jobs=-1)\n",
        "print(\"Tuning hyperparameters...\")\n",
        "search.fit(X_train, y_train)\n",
        "best_clf = search.best_estimator_\n",
        "print(f\"Best params: {search.best_params_}\")\n",
        "\n",
        "# 5. Evaluate on test set\n",
        "X_test, y_test = preprocess_test(test_df, scaler, target_enc, feat_enc, feat_cols)\n",
        "y_pred = best_clf.predict(X_test)\n",
        "acc = accuracy_score(y_test, y_pred)\n",
        "print(f\"Test Accuracy after tuning: {acc * 100:.2f}%\")\n",
        "print(classification_report(y_test, y_pred, target_names=target_enc.classes_))\n",
        "\n",
        "# 6. Save artifacts\n",
        "joblib.dump(best_clf, MODEL_PATH)\n",
        "joblib.dump(scaler, SCALER_PATH)\n",
        "joblib.dump(target_enc, TARGET_ENCODER_PATH)\n",
        "joblib.dump(feat_enc, FEATURE_ENCODERS_PATH)\n",
        "joblib.dump(feat_cols, FEATURE_COLS_PATH)\n",
        "print(\"Saved tuned model and preprocessors.\")\n",
        "\n",
        "# 7. Inference function for real-world (no labels)\n",
        "def infer(input_df):\n",
        "    X_scaled, _ = preprocess_test(input_df, scaler, target_enc, feat_enc, feat_cols)\n",
        "    preds = best_clf.predict(X_scaled)\n",
        "    return target_enc.inverse_transform(preds)\n",
        "\n",
        "# Dataset recommendations:\n",
        "# • UNSW-NB15: https://www.kaggle.com/datasets/ahmedbesbes/unsw-nb15\n",
        "# • CIC-IDS2017 (more realistic, varied attack types): https://www.unb.ca/cic/datasets/ids-2017.html"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JQQ542mvgkWl",
        "outputId": "342ab743-ebcf-4988-a56e-47bff3e38f0d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tuning hyperparameters...\n",
            "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n"
          ]
        }
      ]
    }
  ]
}